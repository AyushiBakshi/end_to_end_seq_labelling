Found 17493 unique words (203621 in total)
Found 75 unique characters
Found 19 unique named entity tags
14041 / 3250 / 3453 sentences in train / dev / test.
Loaded 400001 pretrained embeddings.
word_to_id:  17493
Initialising model for Char Mode: CNN , Encoder Mode: CNN_DILATED, CRF: 1 
/home/arpit9295_2/Ayushi_Workspace/end_to_end_seq_labelling/main.py:136: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.
  nn.init.uniform(input_embedding, -bias, bias)
/home/arpit9295_2/Ayushi_Workspace/end_to_end_seq_labelling/main.py:624: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.
  nn.init.xavier_uniform(self.conv1.weight)
/home/arpit9295_2/Ayushi_Workspace/end_to_end_seq_labelling/main.py:625: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.
  nn.init.xavier_uniform(self.conv2.weight)
/home/arpit9295_2/Ayushi_Workspace/end_to_end_seq_labelling/main.py:626: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.
  nn.init.xavier_uniform(self.conv3.weight)
/home/arpit9295_2/Ayushi_Workspace/end_to_end_seq_labelling/main.py:143: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.
  nn.init.uniform(input_linear.weight, -bias, bias)
EPOCH: 1
/home/arpit9295_2/Ayushi_Workspace/end_to_end_seq_labelling/main.py:840: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.
  torch.nn.utils.clip_grad_norm(model.parameters(), gradient_clip)
2000 :  0.6640742098996275
4000 :  0.3044134400950786
6000 :  0.2883336745674238
8000 :  0.24182032580302448
10000 :  0.2692902960827341
12000 :  0.22366928237138947
14000 :  0.22625740840012284
EPOCH: 2
16000 :  0.179300983807898
18000 :  0.19879755062149596
20000 :  0.185460340770735
22000 :  0.16069857594268355
24000 :  0.18135769854898517
26000 :  0.16914664387411457
28000 :  0.1694222465680725
EPOCH: 3
30000 :  0.1317453076442508
32000 :  0.13432898065892945
34000 :  0.14073247920119308
36000 :  0.13329228705533108
38000 :  0.13000117505133113
40000 :  0.12435441157242912
42000 :  0.12504313633777697
EPOCH: 4
44000 :  0.1025613960850444
46000 :  0.1054002721824807
48000 :  0.10766243177765682
50000 :  0.1078232464927777
52000 :  0.10477790813346019
54000 :  0.09006142593500474
56000 :  0.09186034367791
Train: new_F: 0.9122185681760687 best_F: -1.0 
Accuracy: 0.9020637898686679
Dev: new_F: 0.8272510091440811 best_F: -1.0 
Accuracy: 0.8098387096774193
Saving Model to  ./models/self-trained-model
Test: new_F: 0.7622823651094639 best_F: -1.0 
Accuracy: 0.7409517426273459
EPOCH: 5
58000 :  0.08293617948591324
60000 :  0.09221666142000583
62000 :  0.08464795306160983
64000 :  0.10889440898465592
66000 :  0.0896984070913813
68000 :  0.09805298553634499
70000 :  0.0902851049236955
EPOCH: 6
72000 :  0.06528524583234573
74000 :  0.06900328417131173
76000 :  0.07200938099202485
78000 :  0.07895623606059357
80000 :  0.07167716396128745
82000 :  0.07503128158559855
84000 :  0.07893195187853577
EPOCH: 7
86000 :  0.06163312335773543
88000 :  0.05687119891959635
90000 :  0.06003953060803376
92000 :  0.0499181579171026
94000 :  0.05961193823549402
96000 :  0.06879643712483932
98000 :  0.07596874883687671
EPOCH: 8
100000 :  0.04641789481757095
102000 :  0.05859394152635943
104000 :  0.061759424987516
106000 :  0.060121635478629754
108000 :  0.05329632322557868
110000 :  0.05113733222327755
112000 :  0.04655281479997792
Train: new_F: 0.9504121696269228 best_F: 0.9122185681760687 
Accuracy: 0.9470720243892111
Dev: new_F: 0.8404617556681339 best_F: 0.8272510091440811 
Accuracy: 0.8292363159619797
Saving Model to  ./models/self-trained-model
Test: new_F: 0.7568460401634357 best_F: 0.7622823651094639 
Accuracy: 0.7416936445731811
EPOCH: 9
114000 :  0.037593476257500896
116000 :  0.04675662210934413
118000 :  0.04182043815869471
120000 :  0.047785644349364435
122000 :  0.05013471352261487
124000 :  0.06278243265036483
126000 :  0.05226426089397376
EPOCH: 10
128000 :  0.04201268241119668
130000 :  0.04557790144518093
132000 :  0.04417623874735979
134000 :  0.03955416689120169
136000 :  0.038266504426386225
138000 :  0.0474405450246069
140000 :  0.05205596796511319
EPOCH: 11
142000 :  0.041726960313386165
144000 :  0.03497267466869591
146000 :  0.03883440511632204
148000 :  0.0443086740364952
150000 :  0.028353187185444023
152000 :  0.050527330187744905
154000 :  0.04039179022059263
EPOCH: 12
156000 :  0.040302133577195975
158000 :  0.04300122520410348
160000 :  0.04780317130227649
162000 :  0.045085463184050524
164000 :  0.04184967569115721
166000 :  0.03292516254158468
168000 :  0.02950694430675572
Train: new_F: 0.9607788832314281 best_F: 0.9504121696269228 
Accuracy: 0.9600221389645777
Dev: new_F: 0.8360053440213762 best_F: 0.8404617556681339 
Accuracy: 0.8292198111644856
Test: new_F: 0.7631901840490798 best_F: 0.7622823651094639 
Accuracy: 0.753808864265928
EPOCH: 13
170000 :  0.028625408533966144
172000 :  0.026748321679918436
174000 :  0.032536559952464905
176000 :  0.04540744246290642
178000 :  0.028277548558038917
180000 :  0.03679605550320034
182000 :  0.04147594725183902
EPOCH: 14
184000 :  0.03678405173902352
186000 :  0.03038237196071306
188000 :  0.032188140220854394
190000 :  0.03661247349577413
192000 :  0.037111306640397766
194000 :  0.031030747029025682
196000 :  0.022221063425845646
Time Taken: 43.26954528093338
Losses: [0.6640742098996275, 0.6640742098996275, 0.3044134400950786, 0.2883336745674238, 0.24182032580302448, 0.2692902960827341, 0.22366928237138947, 0.22625740840012284, 0.179300983807898, 0.19879755062149596, 0.185460340770735, 0.16069857594268355, 0.18135769854898517, 0.16914664387411457, 0.1694222465680725, 0.1317453076442508, 0.13432898065892945, 0.14073247920119308, 0.13329228705533108, 0.13000117505133113, 0.12435441157242912, 0.12504313633777697, 0.1025613960850444, 0.1054002721824807, 0.10766243177765682, 0.1078232464927777, 0.10477790813346019, 0.09006142593500474, 0.09186034367791, 0.08293617948591324, 0.09221666142000583, 0.08464795306160983, 0.10889440898465592, 0.0896984070913813, 0.09805298553634499, 0.0902851049236955, 0.06528524583234573, 0.06900328417131173, 0.07200938099202485, 0.07895623606059357, 0.07167716396128745, 0.07503128158559855, 0.07893195187853577, 0.06163312335773543, 0.05687119891959635, 0.06003953060803376, 0.0499181579171026, 0.05961193823549402, 0.06879643712483932, 0.07596874883687671, 0.04641789481757095, 0.05859394152635943, 0.061759424987516, 0.060121635478629754, 0.05329632322557868, 0.05113733222327755, 0.04655281479997792, 0.037593476257500896, 0.04675662210934413, 0.04182043815869471, 0.047785644349364435, 0.05013471352261487, 0.06278243265036483, 0.05226426089397376, 0.04201268241119668, 0.04557790144518093, 0.04417623874735979, 0.03955416689120169, 0.038266504426386225, 0.0474405450246069, 0.05205596796511319, 0.041726960313386165, 0.03497267466869591, 0.03883440511632204, 0.0443086740364952, 0.028353187185444023, 0.050527330187744905, 0.04039179022059263, 0.040302133577195975, 0.04300122520410348, 0.04780317130227649, 0.045085463184050524, 0.04184967569115721, 0.03292516254158468, 0.02950694430675572, 0.028625408533966144, 0.026748321679918436, 0.032536559952464905, 0.04540744246290642, 0.028277548558038917, 0.03679605550320034, 0.04147594725183902, 0.03678405173902352, 0.03038237196071306, 0.032188140220854394, 0.03661247349577413, 0.037111306640397766, 0.031030747029025682, 0.022221063425845646]
Total Params in the model are: 2403055
[[0, 0, 0], [0.9122185681760687, 0.8272510091440811, 0.7622823651094639], [0.9504121696269228, 0.8404617556681339, 0.7568460401634357], [0.9607788832314281, 0.8360053440213762, 0.7631901840490798]]
Best Val Score: 0.8404617556681339
Best Test Score 0.7568460401634357
Prediction:
word : tag
Jay : ORG
is : NA
from : NA
India : LOC


Donald : PER
is : NA
the : NA
president : NA
of : NA
USA : LOC