Found 17493 unique words (203621 in total)
Found 75 unique characters
Found 19 unique named entity tags
14041 / 3250 / 3453 sentences in train / dev / test.
Loaded 400001 pretrained embeddings.
word_to_id:  17493
Initialising model for Char Mode: LSTM , Encoder Mode: CNN, CRF: 1 
/home/arpit9295_2/Ayushi_Workspace/end_to_end_seq_labelling/main.py:136: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.
  nn.init.uniform(input_embedding, -bias, bias)
/home/arpit9295_2/Ayushi_Workspace/end_to_end_seq_labelling/main.py:171: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.
  nn.init.uniform(weight, -sampling_range, sampling_range)
/home/arpit9295_2/Ayushi_Workspace/end_to_end_seq_labelling/main.py:176: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.
  nn.init.uniform(weight, -sampling_range, sampling_range)
/home/arpit9295_2/Ayushi_Workspace/end_to_end_seq_labelling/main.py:183: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.
  nn.init.uniform(weight, -sampling_range, sampling_range)
/home/arpit9295_2/Ayushi_Workspace/end_to_end_seq_labelling/main.py:186: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.
  nn.init.uniform(weight, -sampling_range, sampling_range)
/home/arpit9295_2/Ayushi_Workspace/end_to_end_seq_labelling/main.py:578: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.
  nn.init.xavier_uniform(self.conv1.weight)
embedding_dim=100, char_lstm_dim=50, in=150
/home/arpit9295_2/Ayushi_Workspace/end_to_end_seq_labelling/main.py:143: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.
  nn.init.uniform(input_linear.weight, -bias, bias)
EPOCH: 1
/home/arpit9295_2/Ayushi_Workspace/end_to_end_seq_labelling/main.py:840: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.
  torch.nn.utils.clip_grad_norm(model.parameters(), gradient_clip)
2000 :  0.8443697150631616
4000 :  0.5271816733270023
6000 :  0.44092293153996115
8000 :  0.3996114890393519
10000 :  0.3680047605398892
12000 :  0.3379459447353352
14000 :  0.30236646785895954
EPOCH: 2
16000 :  0.24318806929354797
18000 :  0.24095039532414286
20000 :  0.24584863857525116
22000 :  0.2381879844094836
24000 :  0.23591571838514172
26000 :  0.22697175010085546
28000 :  0.2274779132168066
EPOCH: 3
30000 :  0.19450093233967292
32000 :  0.1927751078072228
34000 :  0.18108886582416067
36000 :  0.1838634467144035
38000 :  0.19726714416453314
40000 :  0.20108827394958156
42000 :  0.1843979914132221
EPOCH: 4
44000 :  0.1754547623109536
46000 :  0.1645558908438886
48000 :  0.18536814515149866
50000 :  0.17477412517803223
52000 :  0.15881471182851495
54000 :  0.16398091347398502
56000 :  0.17243531275271373
Train: new_F: 0.7203514562240757 best_F: -1.0 
Accuracy: 0.755037165162919
Dev: new_F: 0.6417752729834448 best_F: -1.0 
Accuracy: 0.6726970647960125
Saving Model to  ./models/self-trained-model
Test: new_F: 0.5988658547922283 best_F: -1.0 
Accuracy: 0.6287331641616241
EPOCH: 5
58000 :  0.16193940899505288
60000 :  0.1652723927769006
62000 :  0.14037452436206233
64000 :  0.15874037422217852
66000 :  0.14969849254972076
68000 :  0.1574142749771774
70000 :  0.16446186733610305
EPOCH: 6
72000 :  0.14847001257935344
74000 :  0.1374048806180125
76000 :  0.1606131582543298
78000 :  0.14455460114479776
80000 :  0.14059549510775274
82000 :  0.14891623239379193
84000 :  0.14526363341409634
EPOCH: 7
86000 :  0.1379184276216735
88000 :  0.12676117472534046
90000 :  0.13846950201838865
92000 :  0.14403075505997667
94000 :  0.13757938216107493
96000 :  0.1450085570999925
98000 :  0.14794692614939972
EPOCH: 8
100000 :  0.12958465393182908
102000 :  0.138620599276473
104000 :  0.13986000287403622
106000 :  0.12963288135658776
108000 :  0.13145081448079085
110000 :  0.1436940516509482
112000 :  0.1294645394603507
Train: new_F: 0.8571062685420356 best_F: 0.7203514562240757 
Accuracy: 0.8580035894368002
Dev: new_F: 0.7565756408108559 best_F: 0.6417752729834448 
Accuracy: 0.7527921320220037
Saving Model to  ./models/self-trained-model
Test: new_F: 0.6993475577499559 best_F: 0.5988658547922283 
Accuracy: 0.6948142957252978
EPOCH: 9
114000 :  0.10953597479079098
116000 :  0.14650081958070998
118000 :  0.11611364076454186
120000 :  0.12712286317817878
122000 :  0.14446773970449972
124000 :  0.12373200368113504
126000 :  0.12629462769229272
EPOCH: 10
128000 :  0.11774409069686495
130000 :  0.11169118236339202
132000 :  0.13418365443853528
134000 :  0.11892439418551198
136000 :  0.1171540361017921
138000 :  0.14003762329924652
140000 :  0.12327061744492081
EPOCH: 11
142000 :  0.11759189451154721
144000 :  0.11931449230570856
146000 :  0.1166520562110166
148000 :  0.11399821786679097
150000 :  0.12263498043751844
152000 :  0.11333572529769184
154000 :  0.12597175050352222
EPOCH: 12
156000 :  0.11870499222809829
158000 :  0.11705177693780054
160000 :  0.11520091879191106
162000 :  0.10698397606204366
164000 :  0.11539692132178403
166000 :  0.14251641476985927
168000 :  0.11860134573802246
Train: new_F: 0.8522940474159988 best_F: 0.8571062685420356 
Accuracy: 0.852257706903168
Dev: new_F: 0.7357166722352154 best_F: 0.7565756408108559 
Accuracy: 0.729985082048732
Test: new_F: 0.6778593913955928 best_F: 0.6993475577499559 
Accuracy: 0.6680455015511892
EPOCH: 13
170000 :  0.11013899011203276
172000 :  0.11356949525461413
174000 :  0.10839116656706625
176000 :  0.1137382670550432
178000 :  0.11256840709699611
180000 :  0.11173924552544587
182000 :  0.11326152852500888
EPOCH: 14
184000 :  0.0944767280084104
186000 :  0.10957674875179008
188000 :  0.12348282793875795
190000 :  0.10982720922921978
192000 :  0.10245262472710988
194000 :  0.11255937203722641
196000 :  0.11712874407372828
Time Taken: 72.5154310544332
Losses: [0.8443697150631616, 0.8443697150631616, 0.5271816733270023, 0.44092293153996115, 0.3996114890393519, 0.3680047605398892, 0.3379459447353352, 0.30236646785895954, 0.24318806929354797, 0.24095039532414286, 0.24584863857525116, 0.2381879844094836, 0.23591571838514172, 0.22697175010085546, 0.2274779132168066, 0.19450093233967292, 0.1927751078072228, 0.18108886582416067, 0.1838634467144035, 0.19726714416453314, 0.20108827394958156, 0.1843979914132221, 0.1754547623109536, 0.1645558908438886, 0.18536814515149866, 0.17477412517803223, 0.15881471182851495, 0.16398091347398502, 0.17243531275271373, 0.16193940899505288, 0.1652723927769006, 0.14037452436206233, 0.15874037422217852, 0.14969849254972076, 0.1574142749771774, 0.16446186733610305, 0.14847001257935344, 0.1374048806180125, 0.1606131582543298, 0.14455460114479776, 0.14059549510775274, 0.14891623239379193, 0.14526363341409634, 0.1379184276216735, 0.12676117472534046, 0.13846950201838865, 0.14403075505997667, 0.13757938216107493, 0.1450085570999925, 0.14794692614939972, 0.12958465393182908, 0.138620599276473, 0.13986000287403622, 0.12963288135658776, 0.13145081448079085, 0.1436940516509482, 0.1294645394603507, 0.10953597479079098, 0.14650081958070998, 0.11611364076454186, 0.12712286317817878, 0.14446773970449972, 0.12373200368113504, 0.12629462769229272, 0.11774409069686495, 0.11169118236339202, 0.13418365443853528, 0.11892439418551198, 0.1171540361017921, 0.14003762329924652, 0.12327061744492081, 0.11759189451154721, 0.11931449230570856, 0.1166520562110166, 0.11399821786679097, 0.12263498043751844, 0.11333572529769184, 0.12597175050352222, 0.11870499222809829, 0.11705177693780054, 0.11520091879191106, 0.10698397606204366, 0.11539692132178403, 0.14251641476985927, 0.11860134573802246, 0.11013899011203276, 0.11356949525461413, 0.10839116656706625, 0.1137382670550432, 0.11256840709699611, 0.11173924552544587, 0.11326152852500888, 0.0944767280084104, 0.10957674875179008, 0.12348282793875795, 0.10982720922921978, 0.10245262472710988, 0.11255937203722641, 0.11712874407372828]
Total Params in the model are: 1770355
[[0, 0, 0], [0.7203514562240757, 0.6417752729834448, 0.5988658547922283], [0.8571062685420356, 0.7565756408108559, 0.6993475577499559], [0.8522940474159988, 0.7357166722352154, 0.6778593913955928]]
Best Val Score: 0.7565756408108559
Best Test Score 0.6993475577499559