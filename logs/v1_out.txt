Found 17493 unique words (203621 in total)
Found 75 unique characters
Found 19 unique named entity tags
14041 / 3250 / 3453 sentences in train / dev / test.
Loaded 400001 pretrained embeddings.
word_to_id:  17493
Initialising model for Char Mode: CNN , Encoder Mode: CNN, CRF: 1 
/home/arpit9295_2/Ayushi_Workspace/end_to_end_seq_labelling/main.py:136: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.
  nn.init.uniform(input_embedding, -bias, bias)
/home/arpit9295_2/Ayushi_Workspace/end_to_end_seq_labelling/main.py:578: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.
  nn.init.xavier_uniform(self.conv1.weight)
embedding_dim=100, self.out_channels=25, in=125
/home/arpit9295_2/Ayushi_Workspace/end_to_end_seq_labelling/main.py:143: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.
  nn.init.uniform(input_linear.weight, -bias, bias)
EPOCH: 1
/home/arpit9295_2/Ayushi_Workspace/end_to_end_seq_labelling/main.py:840: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.
  torch.nn.utils.clip_grad_norm(model.parameters(), gradient_clip)
2000 :  0.7450049653965435
4000 :  0.4551425357366274
6000 :  0.3458699934877162
8000 :  0.3041035842022371
10000 :  0.26749912261307357
12000 :  0.24712968600050964
14000 :  0.24893852539987985
EPOCH: 2
16000 :  0.25733049864145857
18000 :  0.2001050896754519
20000 :  0.22193908727383876
22000 :  0.17757886310692056
24000 :  0.20824854151993502
26000 :  0.17607187702369695
28000 :  0.20677570393182335
EPOCH: 3
30000 :  0.1685655761842259
32000 :  0.22217575095665995
34000 :  0.17012071210496033
36000 :  0.15941271230841977
38000 :  0.1740657585897344
40000 :  0.14913838680401306
42000 :  0.17113395904430034
EPOCH: 4
44000 :  0.15709555414715246
46000 :  0.13067423091787314
48000 :  0.15034241832591225
50000 :  0.1674541305823211
52000 :  0.1587360770438985
54000 :  0.15885639456745684
56000 :  0.15756009717792843
Train: new_F: 0.8960888194693628 best_F: -1.0 
Accuracy: 0.887193847697066
Dev: new_F: 0.7893959290873276 best_F: -1.0 
Accuracy: 0.7700560448358686
Saving Model to  ./models/self-trained-model
Test: new_F: 0.696813977389517 best_F: -1.0 
Accuracy: 0.6732869910625621
EPOCH: 5
58000 :  0.14274677266018912
60000 :  0.162431077324306
62000 :  0.1435673795164122
64000 :  0.13338179794114735
66000 :  0.11014080158855188
68000 :  0.14531654803423205
70000 :  0.13315604657255445
EPOCH: 6
72000 :  0.12884576019750427
74000 :  0.1342335724378819
76000 :  0.11306388650791172
78000 :  0.12341677873592531
80000 :  0.11011880735003957
82000 :  0.1423785902081072
84000 :  0.13642946434829623
EPOCH: 7
86000 :  0.11023433104532444
88000 :  0.12347802074503668
90000 :  0.11741524670853108
92000 :  0.12960807560361856
94000 :  0.1310096748946227
96000 :  0.11164402212395416
98000 :  0.10710348331195924
EPOCH: 8
100000 :  0.08611537652601606
102000 :  0.11369293418500889
104000 :  0.10368917536013036
106000 :  0.115199935665958
108000 :  0.105031178686186
110000 :  0.107117084962829
112000 :  0.13146029134167755
Train: new_F: 0.8866297112771012 best_F: 0.8960888194693628 
Accuracy: 0.8900395324853901
Dev: new_F: 0.7816895547232625 best_F: 0.7893959290873276 
Accuracy: 0.7728768926925609
Test: new_F: 0.7111304347826086 best_F: 0.696813977389517 
Accuracy: 0.6970678486191613
EPOCH: 9
114000 :  0.11361298477133668
116000 :  0.10320996523324842
118000 :  0.09245221090995809
120000 :  0.10514365178412056
122000 :  0.10729110398087476
124000 :  0.10325106272620325
126000 :  0.12434432139643832
EPOCH: 10
128000 :  0.08160036425399221
130000 :  0.09812283830251774
132000 :  0.10593588427771211
134000 :  0.11241728688087452
136000 :  0.11419955427467986
138000 :  0.09613244361902064
140000 :  0.09235660033159404
EPOCH: 11
142000 :  0.10426540159401468
144000 :  0.09392187499789505
146000 :  0.10643735623946188
148000 :  0.09180431806571474
150000 :  0.08893712076671169
152000 :  0.1017665303926846
154000 :  0.09818677572713089
EPOCH: 12
156000 :  0.09802913432524246
158000 :  0.10481225105458791
160000 :  0.08855100292264755
162000 :  0.09932113800984213
164000 :  0.08808569110517366
166000 :  0.08463734712768864
168000 :  0.08883172120512292
Train: new_F: 0.9202095935929113 best_F: 0.8960888194693628 
Accuracy: 0.9193088479380347
Dev: new_F: 0.8010627698439057 best_F: 0.7893959290873276 
Accuracy: 0.7901719901719901
Saving Model to  ./models/self-trained-model
Test: new_F: 0.7083550460309188 best_F: 0.7111304347826086 
Accuracy: 0.6935374149659864
EPOCH: 13
170000 :  0.08221650887970874
172000 :  0.07674101690544687
174000 :  0.10226696079051072
176000 :  0.08627327713800918
178000 :  0.09381613206121138
180000 :  0.10996248519448214
182000 :  0.09186750586627565
EPOCH: 14
184000 :  0.07751363662734027
186000 :  0.08401822125736197
188000 :  0.09448678543578887
190000 :  0.07812902955758809
192000 :  0.09376722896612621
194000 :  0.07571643052950452
196000 :  0.08035311187377026
Time Taken: 42.19049916664759
Losses: [0.7450049653965435, 0.7450049653965435, 0.4551425357366274, 0.3458699934877162, 0.3041035842022371, 0.26749912261307357, 0.24712968600050964, 0.24893852539987985, 0.25733049864145857, 0.2001050896754519, 0.22193908727383876, 0.17757886310692056, 0.20824854151993502, 0.17607187702369695, 0.20677570393182335, 0.1685655761842259, 0.22217575095665995, 0.17012071210496033, 0.15941271230841977, 0.1740657585897344, 0.14913838680401306, 0.17113395904430034, 0.15709555414715246, 0.13067423091787314, 0.15034241832591225, 0.1674541305823211, 0.1587360770438985, 0.15885639456745684, 0.15756009717792843, 0.14274677266018912, 0.162431077324306, 0.1435673795164122, 0.13338179794114735, 0.11014080158855188, 0.14531654803423205, 0.13315604657255445, 0.12884576019750427, 0.1342335724378819, 0.11306388650791172, 0.12341677873592531, 0.11011880735003957, 0.1423785902081072, 0.13642946434829623, 0.11023433104532444, 0.12347802074503668, 0.11741524670853108, 0.12960807560361856, 0.1310096748946227, 0.11164402212395416, 0.10710348331195924, 0.08611537652601606, 0.11369293418500889, 0.10368917536013036, 0.115199935665958, 0.105031178686186, 0.107117084962829, 0.13146029134167755, 0.11361298477133668, 0.10320996523324842, 0.09245221090995809, 0.10514365178412056, 0.10729110398087476, 0.10325106272620325, 0.12434432139643832, 0.08160036425399221, 0.09812283830251774, 0.10593588427771211, 0.11241728688087452, 0.11419955427467986, 0.09613244361902064, 0.09235660033159404, 0.10426540159401468, 0.09392187499789505, 0.10643735623946188, 0.09180431806571474, 0.08893712076671169, 0.1017665303926846, 0.09818677572713089, 0.09802913432524246, 0.10481225105458791, 0.08855100292264755, 0.09932113800984213, 0.08808569110517366, 0.08463734712768864, 0.08883172120512292, 0.08221650887970874, 0.07674101690544687, 0.10226696079051072, 0.08627327713800918, 0.09381613206121138, 0.10996248519448214, 0.09186750586627565, 0.07751363662734027, 0.08401822125736197, 0.09448678543578887, 0.07812902955758809, 0.09376722896612621, 0.07571643052950452, 0.08035311187377026]
Total Params in the model are: 1761855
[[0, 0, 0], [0.8960888194693628, 0.7893959290873276, 0.696813977389517], [0.8866297112771012, 0.7816895547232625, 0.7111304347826086], [0.9202095935929113, 0.8010627698439057, 0.7083550460309188]]
Best Val Score: 0.8010627698439057
Best Test Score 0.7083550460309188

