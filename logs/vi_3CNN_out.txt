Found 17493 unique words (203621 in total)
Found 75 unique characters
Found 19 unique named entity tags
14041 / 3250 / 3453 sentences in train / dev / test.
Loaded 400001 pretrained embeddings.
word_to_id:  17493
Initialising model for Char Mode: CNN , Encoder Mode: CNN3, CRF: 1 
/home/arpit9295_2/Ayushi_Workspace/end_to_end_seq_labelling/main.py:136: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.
  nn.init.uniform(input_embedding, -bias, bias)
/home/arpit9295_2/Ayushi_Workspace/end_to_end_seq_labelling/main.py:608: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.
  nn.init.xavier_uniform(self.conv1.weight)
/home/arpit9295_2/Ayushi_Workspace/end_to_end_seq_labelling/main.py:609: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.
  nn.init.xavier_uniform(self.conv2.weight)
/home/arpit9295_2/Ayushi_Workspace/end_to_end_seq_labelling/main.py:610: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.
  nn.init.xavier_uniform(self.conv3.weight)
/home/arpit9295_2/Ayushi_Workspace/end_to_end_seq_labelling/main.py:143: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.
  nn.init.uniform(input_linear.weight, -bias, bias)
EPOCH: 1
/home/arpit9295_2/Ayushi_Workspace/end_to_end_seq_labelling/main.py:840: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.
  torch.nn.utils.clip_grad_norm(model.parameters(), gradient_clip)
2000 :  0.8872252149910076
4000 :  0.39529801843682466
6000 :  0.3466556888268241
8000 :  0.277130286472941
10000 :  0.2561550447586148
12000 :  0.2385867844079225
14000 :  0.23625309175472556
EPOCH: 2
16000 :  0.18100545914956798
18000 :  0.17690356298323934
20000 :  0.1932984735354229
22000 :  0.16537470300241772
24000 :  0.15755887068592112
26000 :  0.16645017739037327
28000 :  0.1651259992731708
EPOCH: 3
30000 :  0.12166172868918691
32000 :  0.13508819982440062
34000 :  0.11328424207474216
36000 :  0.1426069928986802
38000 :  0.11702065825109846
40000 :  0.120643524549298
42000 :  0.10902492469634785
EPOCH: 4
44000 :  0.08762003873951116
46000 :  0.10768342244399363
48000 :  0.08255007711583297
50000 :  0.1037019600434502
52000 :  0.09400569924116425
54000 :  0.11595061286860583
56000 :  0.10583952445134605
Train: new_F: 0.9199966243301406 best_F: -1.0 
Accuracy: 0.9104689522695953
Dev: new_F: 0.799966991252682 best_F: -1.0 
Accuracy: 0.7844311377245509
Saving Model to  ./models/self-trained-model
Test: new_F: 0.7163145133356424 best_F: -1.0 
Accuracy: 0.6993574568819749
EPOCH: 5
58000 :  0.08290796555462997
60000 :  0.07771091580176775
62000 :  0.0850897384714408
64000 :  0.0802855516997508
66000 :  0.08582372975210939
68000 :  0.07758438119874783
70000 :  0.08530504229233751
EPOCH: 6
72000 :  0.06319856047470229
74000 :  0.062957679660411
76000 :  0.07627728309590384
78000 :  0.06470814464558511
80000 :  0.06900237098687355
82000 :  0.07409045862890033
84000 :  0.0791196392409009
EPOCH: 7
86000 :  0.06117786880154061
88000 :  0.06500341590668737
90000 :  0.0668799777798319
92000 :  0.06525049207349311
94000 :  0.05768484709593819
96000 :  0.0643743994109451
98000 :  0.05687374285195966
EPOCH: 8
100000 :  0.0608050515154426
102000 :  0.0557759102007825
104000 :  0.06032691328486477
106000 :  0.05229324131187163
108000 :  0.0523012244917921
110000 :  0.05637058136523359
112000 :  0.0503658041556705
Train: new_F: 0.9556136880835407 best_F: 0.9199966243301406 
Accuracy: 0.9532416836388323
Dev: new_F: 0.814253600865873 best_F: 0.799966991252682 
Accuracy: 0.8053359683794467
Saving Model to  ./models/self-trained-model
Test: new_F: 0.721717877094972 best_F: 0.7163145133356424 
Accuracy: 0.7100652696667812
EPOCH: 9
114000 :  0.053706197367408476
116000 :  0.053663205709537094
118000 :  0.04672746912149081
120000 :  0.04983763468917664
122000 :  0.048360537305328126
124000 :  0.05652069483869773
126000 :  0.044575233902948194
EPOCH: 10
128000 :  0.03844784925420615
130000 :  0.049753436568084924
132000 :  0.04635114462347305
134000 :  0.04968901897283925
136000 :  0.04578235857282041
138000 :  0.052057113657446134
140000 :  0.052010185413068385
EPOCH: 11
142000 :  0.042954073836755285
144000 :  0.03390070426831433
146000 :  0.041202335859254126
148000 :  0.04927596905886048
150000 :  0.048492023481509924
152000 :  0.042026089225378475
154000 :  0.0473583429987529
EPOCH: 12
156000 :  0.03561174061050716
158000 :  0.036431109087189294
160000 :  0.04105198617049164
162000 :  0.04470006158166585
164000 :  0.04227753747842668
166000 :  0.038626695863538126
168000 :  0.04608883186143664
Train: new_F: 0.9659153849431213 best_F: 0.9556136880835407 
Accuracy: 0.9650930143459198
Dev: new_F: 0.8036042049057234 best_F: 0.814253600865873 
Accuracy: 0.796427980816934
Test: new_F: 0.7186600366396231 best_F: 0.721717877094972 
Accuracy: 0.7066392177045805
EPOCH: 13
170000 :  0.03974531508043108
172000 :  0.037292900958779095
174000 :  0.03546951158365246
176000 :  0.04796308564300966
178000 :  0.04912297616504736
180000 :  0.039458307646867787
182000 :  0.03072923773746898
EPOCH: 14
184000 :  0.04043875616496397
186000 :  0.029746421046149104
188000 :  0.03525250893661595
190000 :  0.03994655265626511
192000 :  0.033144720172813655
194000 :  0.04231039981379987
196000 :  0.04406528158231616
Time Taken: 44.36838975747426
Losses: [0.8872252149910076, 0.8872252149910076, 0.39529801843682466, 0.3466556888268241, 0.277130286472941, 0.2561550447586148, 0.2385867844079225, 0.23625309175472556, 0.18100545914956798, 0.17690356298323934, 0.1932984735354229, 0.16537470300241772, 0.15755887068592112, 0.16645017739037327, 0.1651259992731708, 0.12166172868918691, 0.13508819982440062, 0.11328424207474216, 0.1426069928986802, 0.11702065825109846, 0.120643524549298, 0.10902492469634785, 0.08762003873951116, 0.10768342244399363, 0.08255007711583297, 0.1037019600434502, 0.09400569924116425, 0.11595061286860583, 0.10583952445134605, 0.08290796555462997, 0.07771091580176775, 0.0850897384714408, 0.0802855516997508, 0.08582372975210939, 0.07758438119874783, 0.08530504229233751, 0.06319856047470229, 0.062957679660411, 0.07627728309590384, 0.06470814464558511, 0.06900237098687355, 0.07409045862890033, 0.0791196392409009, 0.06117786880154061, 0.06500341590668737, 0.0668799777798319, 0.06525049207349311, 0.05768484709593819, 0.0643743994109451, 0.05687374285195966, 0.0608050515154426, 0.0557759102007825, 0.06032691328486477, 0.05229324131187163, 0.0523012244917921, 0.05637058136523359, 0.0503658041556705, 0.053706197367408476, 0.053663205709537094, 0.04672746912149081, 0.04983763468917664, 0.048360537305328126, 0.05652069483869773, 0.044575233902948194, 0.03844784925420615, 0.049753436568084924, 0.04635114462347305, 0.04968901897283925, 0.04578235857282041, 0.052057113657446134, 0.052010185413068385, 0.042954073836755285, 0.03390070426831433, 0.041202335859254126, 0.04927596905886048, 0.048492023481509924, 0.042026089225378475, 0.0473583429987529, 0.03561174061050716, 0.036431109087189294, 0.04105198617049164, 0.04470006158166585, 0.04227753747842668, 0.038626695863538126, 0.04608883186143664, 0.03974531508043108, 0.037292900958779095, 0.03546951158365246, 0.04796308564300966, 0.04912297616504736, 0.039458307646867787, 0.03072923773746898, 0.04043875616496397, 0.029746421046149104, 0.03525250893661595, 0.03994655265626511, 0.033144720172813655, 0.04231039981379987, 0.04406528158231616]
Total Params in the model are: 2082655
[[0, 0, 0], [0.9199966243301406, 0.799966991252682, 0.7163145133356424], [0.9556136880835407, 0.814253600865873, 0.721717877094972], [0.9659153849431213, 0.8036042049057234, 0.7186600366396231]]
Best Val Score: 0.814253600865873
Best Test Score 0.721717877094972
Prediction:
word : tag
Jay : NA
is : NA
from : NA
India : LOC


Donald : ORG
is : NA
the : NA
president : NA
of : NA
USA : LOC